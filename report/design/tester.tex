% intro, what is Tester trying to do?
% we want broad language support
Tester is a tool for testing code in a variety of programming languages in a safe and isolated environment. To fulfill the needs of the GPP, Tester needs to support a  broad varierty of languages, so that the range of courses that can benefit from the platform is not limited. Tester also strives for the functionality to test code based on different merits to support the creation of varied, fun and interesting assignments.

\subsection{Sandboxing}
%TODO ref to docker
An important feature of the Tester is that the code is tested in an isolated environment. The main reason behind doing this is that we are executing potentially malicious code. Allowing such code to be executed without isolation is bound to cause service disruptions or information leaks.

To achieve isolation all code testing takes place in so called Docker containers equipped with the tools necessary to compile and run the code. A container is a virtualization (simulation) of an operating-system with a separate user-space. What this means is that programs running inside the container can only access the contents and devices that are assigned to the container. By running the tests in Docker containers, any malicious code cannot gain access to information it shouldn't have access to or cause any disruptions to the service, since such code will at most crash the container which has no long-lasting effects on the service offered by Tester.
\subsection{Manager}
% add discussion of different ways of managing load and what we chose
% (Start containers on demand? Keep a pool of containers ready? Predict load or just react? Allocate different amounts of resources for different languages?)

As Backend sends requests to Tester these requests are handled by assigning a free container serving that request.
When a request for a container with a language that has no free containers that
request is put in queue and handled when a container is ready. Once a request has
been served a container another container of the same type is started to decrease
the response time to Backend. Because on average the containers
take around one second to start.

A problem with starting containers whenever a request has been made
is that each Tester instance has limited hardware capacity. Starting too many
containers will effect the over all performance of the system and therefore
performance per container. And as timing is one of the properties that Tester
examines this will affect the result.

In order to address this issue the Manager has to keep track of which containers
that are started and which containers that are currently doing work. Depending on
hardware it is possible to configure so that a maximum number of containers that
can be started and to specify the maximum number of containers
per supported language as well. It is also possible to configure a number of containers
that should be started even if no request for that language has been made to keep
idling containers ready serve new requests. This is done in order to decrease
response time to Backend.

Another way of handling the amount of containers running at a given time could
be to analyze how high the demand for a specific language has been previously and
then deciding on that result how many containers that needs to run in order to
suffice the number of request on that language. This is not something that has
been implemented but could be done in the future.

Each container is limited to one thread of the processor running at 50\% core speed and
100MB memory. Because of this each time a student run the same code a similar
result can be observed. Timing is always a hard property to measure but with
these settings Tester can deliver similar timings multiple times.

If a container is hijacked by malicious code the Manager has a timeout that will
force the container to exit after a given time and return request timeout status code.

\subsection{Test types}
% unit tests are hard to write
% I/O tests are language-independent which is good if we want broad language support
When deciding which test types had the highest implementation priority, an important factor was the time expenditure required by the creator of the tests. If writing tests for a single assignment takes a considerable amount of time the platform will become too impractical to use. For this reason tests such as Unit Tests are not supported. It would be time-consuming for lab supervisors to write tests. %idk what i wrote here

Another deciding factor is the language-dependency of the unit tests. If a test requires language-specific implementation the extensibility of the language support suffers. This is one of the reasons why the I/O and Code size tests mentioned below are excellent choices, they are both language-independent and require no additional implementation for every language supported. Although Lint tests also mentioned below does not have the independence property, it has been implemented for a smaller number of languages as a proof of concept.
%Should we explain what each test type is? or are they obvious enough?
Currently, Tester supports three types of tests:
\begin{itemize}
\item Input/Output (I/O)
\item Code size
\item Lint
\end{itemize}


\subsection{Extensibility}
In order to achieve broad language support, it needs to be easy to add new languages. Two steps are necessary to add support for a new language:

\begin{itemize}
\item The manager has a makefile that produces docker images for each supported language. The makefile needs to be extended with a new target that installs language-specific dependencies.

\item The Node instance running in the container needs to have a module for each supported language. Each language module exports two functions: \texttt{prepare}, which produces a file that can be run with the \texttt{run} function. The \texttt{prepare} step is used for compiled languages, where a binary must be produced before running the program. Some languages, such as python, are run directly in the interpreter. By making preparation a separate step, the program does not need to be recompiled for each test.
\end{itemize}

\subsection{Service Availability Fallback}
A little known feature of tester is that it plays nice with load-balancers by reporting whether or not the testing service itself is available. That is, if the language that is to be tested isn't available, or the testing-queue is full, it defers the job to another tester. It does that by responding with the \texttt{503: Service Unavailable} status, after which the load-balancer sitting in front of it will understand that it needs to route traffic elsewhere.
