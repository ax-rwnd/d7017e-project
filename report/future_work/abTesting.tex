A/B testing can be applied in various ways to measure how effective improvements and updates are to a service. This essentially means utilizing 2 different groups of users to discover behavioural patterns and interpreting the result from the difference in performance. In GPP this might be used to improve the user interface by finding better color combinations and/or element positions. More importantly, tests could be run by teachers and researchers to determine which elements work and which don't.

One way of implementing this in GPP could be to divide a fraction of the user base into groups, expose them to changes and monitor its effects. For instance, testing the adventure map might show a significant increase in performance for group A whilst group B shows no change. Furthermore, change could possibly be seen in the second group---despite there being no change to the group itself---as the total amount of completed assignments increases in both groups.

Given that enough users participate in the A/B study, it can be shown with statistical significance that a gamification element is either profitable or inconvenient. In extension, this allows examiners to convince their faculties by showing them data proving its usefulness, allowing them to implement it into their courses.
